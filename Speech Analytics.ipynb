{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad48143d",
   "metadata": {},
   "source": [
    "#  Speech Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da952de",
   "metadata": {},
   "source": [
    "###  installing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2173c5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5be21c43",
   "metadata": {},
   "source": [
    "### How to play audio using python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c31a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d6757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "playsound('file.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5774aa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"file.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c76ca",
   "metadata": {},
   "source": [
    "# Text to speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90729a33",
   "metadata": {},
   "source": [
    "### Using gTTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7499f0e0",
   "metadata": {},
   "source": [
    "Text-to-speech (TTS) technology reads the digital, it can take words from user and convert them into Audio.\n",
    "There are many API's are available in Python in order to convert text to speech lets discuss some of them one by one "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101e9577",
   "metadata": {},
   "source": [
    "gTTS API is the Google Text to Speech API <br>\n",
    "'Features'<br>\n",
    "Customizable speech-specific sentence tokenizer that allows for unlimited lengths of text to be read, all while keeping proper intonation, abbreviations, decimals and more;<br>\n",
    "Customizable text pre-processors which can, for example, provide pronunciation corrections<br>\n",
    "Documentation https://gtts.readthedocs.io/en/latest/module.html\n",
    "<br>GTTS is an easy tool to convert text to voice, but it requires an internet connection to operate because it depends entirely on Google to get the audio data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f5cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS,lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06a94c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts = gTTS('Kalash Jindal')\n",
    "tts.save('my.mp3')\n",
    "playsound(\"my.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29113641",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_convert=\"Hello Kalash here Nice to meet you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77916e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts=gTTS(text = text_to_convert, lang ='en', slow = False)\n",
    "tts.save('text_to_convert.mp3')\n",
    "playsound('text_to_convert.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e8b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"file.txt\",\"r\").read().replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944e0a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey  kalash here  lets code '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c806d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts=gTTS(text = file, lang ='en', slow = False)\n",
    "tts.save('file.mp3')\n",
    "playsound('file.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55efe748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'af': 'Afrikaans', 'ar': 'Arabic', 'bn': 'Bengali', 'bs': 'Bosnian', 'ca': 'Catalan', 'cs': 'Czech', 'cy': 'Welsh', 'da': 'Danish', 'de': 'German', 'el': 'Greek', 'en': 'English', 'eo': 'Esperanto', 'es': 'Spanish', 'et': 'Estonian', 'fi': 'Finnish', 'fr': 'French', 'gu': 'Gujarati', 'hi': 'Hindi', 'hr': 'Croatian', 'hu': 'Hungarian', 'hy': 'Armenian', 'id': 'Indonesian', 'is': 'Icelandic', 'it': 'Italian', 'ja': 'Japanese', 'jw': 'Javanese', 'km': 'Khmer', 'kn': 'Kannada', 'ko': 'Korean', 'la': 'Latin', 'lv': 'Latvian', 'mk': 'Macedonian', 'ml': 'Malayalam', 'mr': 'Marathi', 'my': 'Myanmar (Burmese)', 'ne': 'Nepali', 'nl': 'Dutch', 'no': 'Norwegian', 'pl': 'Polish', 'pt': 'Portuguese', 'ro': 'Romanian', 'ru': 'Russian', 'si': 'Sinhala', 'sk': 'Slovak', 'sq': 'Albanian', 'sr': 'Serbian', 'su': 'Sundanese', 'sv': 'Swedish', 'sw': 'Swahili', 'ta': 'Tamil', 'te': 'Telugu', 'th': 'Thai', 'tl': 'Filipino', 'tr': 'Turkish', 'uk': 'Ukrainian', 'ur': 'Urdu', 'vi': 'Vietnamese', 'zh-CN': 'Chinese', 'zh-TW': 'Chinese (Mandarin/Taiwan)', 'zh': 'Chinese (Mandarin)'}\n"
     ]
    }
   ],
   "source": [
    "#Google Translate text-to-speech can speak in different local ‘accents’ just you have to use the language \n",
    "\n",
    "print(lang.tts_langs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ad997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43635992",
   "metadata": {},
   "source": [
    "###  Using pyttx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "230ee87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eff2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b19c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am a data scientist\"\n",
    "engine.say(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3f1567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play the speech\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "289498ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# get details of speaking rate\n",
    "rate = engine.getProperty(\"rate\")\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06ce52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.setProperty(\"rate\", 300)\n",
    "engine.say(text)\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e02a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slower\n",
    "engine.setProperty(\"rate\", 100)\n",
    "engine.say(text)\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26a08472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<pyttsx3.voice.Voice object at 0x000001EB6584CC70>, <pyttsx3.voice.Voice object at 0x000001EB6584CC40>, <pyttsx3.voice.Voice object at 0x000001EB6584C100>]\n"
     ]
    }
   ],
   "source": [
    "voices = engine.getProperty(\"voices\")\n",
    "print(voices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee76ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.setProperty(\"voice\", voices[0].id)\n",
    "engine.say(text)\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33aa121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.save_to_file(text, \"python.mp3\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5559f0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b7b8c94",
   "metadata": {},
   "source": [
    "##### Microsoft speech engine\n",
    "If you use Microsoft Windows 10, it has a speech engine included.\n",
    "Install the module win32com, then you can use this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7741f12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import win32com.client as wincl\n",
    "speak = wincl.Dispatch(\"SAPI.SpVoice\")\n",
    "speak.Speak(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ab88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cbdb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b084ac4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9c96d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11b9062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39f5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de0db36b",
   "metadata": {},
   "source": [
    "# Speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b689cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8e6b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "433fe41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"example.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45e1d222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is about which she had fixed a bug for country seed at a short distance from the city just that what is now called that state should the bonded with proofs of his ingenuity and smoke tax that require host to work some Dutch ovens reverse the meat was held fire caused the month before the horses weathercocks it turned against the wind another 100 ko drive it was established in confounded of beholder\n"
     ]
    }
   ],
   "source": [
    "with sr.AudioFile(filename) as source:\n",
    "    # listen for the data (load audio to memory)\n",
    "    audio_data = r.record(source)\n",
    "    # recognize (convert from speech to text)\n",
    "    text = r.recognize_google(audio_data)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87e9908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import speech_recognition as sr \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# create a speech recognition object\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# a function that splits the audio file into chunks\n",
    "# and applies speech recognition\n",
    "def get_large_audio_transcription(path):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_wav(path)  \n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                print(chunk_filename, \":\", text)\n",
    "                whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "260ce1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-chunks\\chunk1.wav : His about which she had fixed a bug for country seat. \n",
      "audio-chunks\\chunk2.wav : Are short distance to the city. \n",
      "audio-chunks\\chunk3.wav : Just that what is now called dutch street. \n",
      "audio-chunks\\chunk4.wav : Should bounded with proofs of his ingenuity. \n",
      "audio-chunks\\chunk5.wav : And smoke jack. \n",
      "audio-chunks\\chunk6.wav : Required host version. \n",
      "audio-chunks\\chunk7.wav : Church of windsor was to meet without fire. \n",
      "audio-chunks\\chunk8.wav : Chords for the horses. \n",
      "audio-chunks\\chunk9.wav : Weather cox it turned against the wind and other one headed could try with this. \n",
      "audio-chunks\\chunk10.wav : Rustom stand confounded o b holders. \n",
      "\n",
      "Full text: His about which she had fixed a bug for country seat. Are short distance to the city. Just that what is now called dutch street. Should bounded with proofs of his ingenuity. And smoke jack. Required host version. Church of windsor was to meet without fire. Chords for the horses. Weather cox it turned against the wind and other one headed could try with this. Rustom stand confounded o b holders. \n"
     ]
    }
   ],
   "source": [
    "path = \"example.wav\"\n",
    "print(\"\\nFull text:\", get_large_audio_transcription(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d922cb88",
   "metadata": {},
   "source": [
    "#### Now let's use our microphone to convert our speech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4631d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing...\n",
      "how are you\n"
     ]
    }
   ],
   "source": [
    "with sr.Microphone() as source:\n",
    "    # read the audio data from the default microphone\n",
    "    audio_data = r.record(source, duration=5)\n",
    "    print(\"Recognizing...\")\n",
    "    # convert speech to text\n",
    "    text = r.recognize_google(audio_data)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "371b9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r.recognize_google(audio_data, language=\"es-ES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c61a5a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how are you'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e540bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47b24a9e",
   "metadata": {},
   "source": [
    "##### Python provides a module called PyDub to work with audio files. PyDub is a Python library to work with only .wav files.\n",
    "\n",
    "Audio Processing tasks includes:<br>\n",
    "Loading and Playing audio files<br>\n",
    "Getting certain information of file length channels.<br>\n",
    "Increasing/Decreasing volume & pitch<br>\n",
    "Merging audio files<br>\n",
    "Splitting an Audio file.<br>\n",
    "Exporting files<br>\n",
    "Adding some techniques & generating audio tunes<br>\n",
    "All of these can be achieved using Pydub, a simple, well-designed Python module for audio manipulation. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67024981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f023bf6",
   "metadata": {},
   "source": [
    "### Let’s download our first audio using the below url:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad360943",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"http://www.freemusicloops.co.uk/download.aspx?did=266\", \"firstfile.wav\")\n",
    "\n",
    "# Loading the Audio into Python's pydub package\n",
    "audio1 = AudioSegment.from_wav(\"firstfile.wav\")\n",
    "\n",
    "play(audio1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43b393",
   "metadata": {},
   "source": [
    "### Checking basic attributes of the Audio file\n",
    "Check the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa6eabec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pydub.audio_segment.AudioSegment'>\n"
     ]
    }
   ],
   "source": [
    "# data type fo the file\n",
    "print(type(audio1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c7948b",
   "metadata": {},
   "source": [
    "### Check the frame rate of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "361a1841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44100\n"
     ]
    }
   ],
   "source": [
    "# To find frame rate of song/file\n",
    "print(audio1.frame_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6292159c",
   "metadata": {},
   "source": [
    "### To know about the channels of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e88a419b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# To know about channels of file\n",
    "print(audio1.channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a9587b",
   "metadata": {},
   "source": [
    "### Finding the number of bytes per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01379091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Find the number of bytes per sample \n",
    "print(audio1.sample_width )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420965f5",
   "metadata": {},
   "source": [
    "### Finding the maximum amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "414ad7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32768\n"
     ]
    }
   ],
   "source": [
    "# Find Maximum amplitude \n",
    "print(audio1.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4548502c",
   "metadata": {},
   "source": [
    "### To find the length of the audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b2d3947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7376\n"
     ]
    }
   ],
   "source": [
    "# To know length of audio file\n",
    "print(len(audio1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc2b80b",
   "metadata": {},
   "source": [
    "### To change the sample rate of an audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b54b3bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500\n"
     ]
    }
   ],
   "source": [
    "wav_file_new = audio1.set_frame_rate(22500) \n",
    "print(wav_file_new.frame_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bae40",
   "metadata": {},
   "source": [
    "### Increasing/Decreasing Volume\n",
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4576d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the volume by 10 dB \n",
    "new_wav_file = audio1 + 10\n",
    "\n",
    "# Reducing volume by 5\n",
    "silent_wav_file = audio1 - 5\n",
    "\n",
    "# Playing silent file\n",
    "play(silent_wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe64c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing original file \n",
    "play(audio1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ab45311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing louder file\n",
    "play(new_wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10bcc5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adea7cef",
   "metadata": {},
   "source": [
    "### Merging multiple Audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15e7d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the first audio file from the url\n",
    "urllib.request.urlretrieve(\"http://www.freemusicloops.co.uk/download.aspx?did=21\", \"secondfile.wav\")\n",
    "\n",
    "# Loading the Audio into Python's pydub package\n",
    "audio2 = AudioSegment.from_wav(\"secondfile.wav\")\n",
    "\n",
    "play(audio2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1da0bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two audio files \n",
    "audio3 = audio2 + audio1 + audio2 \n",
    "# play the sound \n",
    "play(audio3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a8946",
   "metadata": {},
   "source": [
    "### Exporting Audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34b01cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='audio3.wav'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "audio1.export(out_f = \"audio1.wav\", format = \"wav\")\n",
    "audio2.export(out_f = \"audio2.wav\", format = \"wav\")\n",
    "audio3.export(out_f = \"audio3.wav\", format = \"wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5c30d3",
   "metadata": {},
   "source": [
    "### Splitting Audio: split_to_mono() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15173c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<pydub.audio_segment.AudioSegment object at 0x000001AA30430EE0>, <pydub.audio_segment.AudioSegment object at 0x000001AA304300A0>]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='newaudio3.wav'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split stereo to mono \n",
    "b = audio3.split_to_mono() \n",
    "print(b) \n",
    "print(b[0].channels )\n",
    "\n",
    "b[0].export(out_f=\"newaudio3.wav\",format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c497a02d",
   "metadata": {},
   "source": [
    "### Looping the Audio twice, fade in & fade out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bfc7bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping the audio twice\n",
    "audio1_loop = audio1 * 2\n",
    "play(audio1_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5a60344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the length of audio1_loop in milliseconds \n",
    "length_audio1 = len(audio1_loop) \n",
    "\n",
    "# Setting the fade time for audio 1 \n",
    "audio_1_fadetime = int(length_audio1 * 0.5) \n",
    "\n",
    "# Adding fade in and fade out transitions to audio 1 \n",
    "audio1_final = audio1.fade_in(audio_1_fadetime).fade_out(audio_1_fadetime) \n",
    "play(audio1_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d7da87",
   "metadata": {},
   "source": [
    "### Mixing Audio & generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c01f7c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixing both the audios together\n",
    "mixed_audio = audio2[:1000].overlay(audio1_final)\n",
    "\n",
    "#Alternative way to merge and apply filters\n",
    "\n",
    "# Filtering the audio2's beat at 3KHz\n",
    "filtered_audio2 = audio2.low_pass_filter(3000)\n",
    "\n",
    "# Mixing audio1 with audio2 on a reversed, panned version\n",
    "loop = audio1_loop.reverse().pan(-0.5).overlay(audio1_loop.pan(0.5))\n",
    "\n",
    "# Mix our filtered beat with the new loop at -3dB\n",
    "final_audio = filtered_audio2.overlay(audio1_loop - 3, loop=True)\n",
    "\n",
    "# Looping the audio twice\n",
    "final_audio = final_audio * 2\n",
    "#Code to download the final audio\n",
    "final_audio .export(out_f = \"final.wav\", format = \"wav\")\n",
    "\n",
    "play(final_audio )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a8f217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2905b619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0111ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecb2c154",
   "metadata": {},
   "source": [
    "### saving the audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b48c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "fs = 22500  # Sample rate\n",
    "seconds = 3  # Duration of recording\n",
    "\n",
    "myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=2)\n",
    "sd.wait()  # Wait until recording is finished\n",
    "write('output.wav', fs, myrecording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1fc053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "playsound(\"output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c7fca49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording\n",
      "Finished recording\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "chunk = 1024  # Record in chunks of 1024 samples\n",
    "sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "channels = 2\n",
    "fs = 44100  # Record at 44100 samples per second\n",
    "seconds = 3\n",
    "filename = \"hello_how_are_you.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "\n",
    "print('Recording')\n",
    "\n",
    "stream = p.open(format=sample_format,\n",
    "                channels=channels,\n",
    "                rate=fs,\n",
    "                frames_per_buffer=chunk,\n",
    "                input=True)\n",
    "\n",
    "frames = []  # Initialize array to store frames\n",
    "\n",
    "# Store data in chunks for 3 seconds\n",
    "for i in range(0, int(fs / chunk * seconds)):\n",
    "    data = stream.read(chunk)\n",
    "    frames.append(data)\n",
    "\n",
    "# Stop and close the stream \n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "# Terminate the PortAudio interface\n",
    "p.terminate()\n",
    "\n",
    "print('Finished recording')\n",
    "\n",
    "# Save the recorded data as a WAV file\n",
    "wf = wave.open(filename, 'wb')\n",
    "wf.setnchannels(channels)\n",
    "wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "wf.setframerate(fs)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f4ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "playsound(\"hello_how_are_you.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0ed8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9915336e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x00\\x00\\x00\\x00\\xff\\xff\\x00\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "\n",
    "# Create audio file wave object\n",
    "hello_how_are_you = wave.open(\"hello_how_are_you.wav\", 'r')\n",
    "\n",
    "# Read all frames from wave object \n",
    "signal_hh = hello_how_are_you.readframes(-1)\n",
    "\n",
    "# View first 10\n",
    "print(signal_gm[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e571c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
